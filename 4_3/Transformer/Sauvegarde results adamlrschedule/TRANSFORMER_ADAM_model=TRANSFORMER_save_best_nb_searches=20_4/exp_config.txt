batch_size    64
best_val    None
code_file    randomSearch.py
data    data
debug    False
dp_keep_prob    0.85
early_stopped    No
emb_size    200
evaluate    False
hidden_size    1024
initial_lr    0.001
model    TRANSFORMER
n_heads    8
nb_searches    20
num_epochs    40
num_layers    1
optimizer    ADAM
patience    5
save_best    True
save_dir    TRANSFORMER_ADAM_model=TRANSFORMER_save_best_nb_searches=20_4
seed    1111
seq_len    40
